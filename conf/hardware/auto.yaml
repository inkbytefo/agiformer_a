
# Hardware and runtime configuration

# Device selection:
# - "auto": use CUDA if available, else CPU
# - "cuda": force CUDA
# - "cpu": force CPU
device: auto

# Safe CUDA allocator configuration for PyTorch 2.x
# Parsed and validated in train.main()(train.py:253)
# Examples:
#   "expandable_segments"
#   "max_split_size_mb:128"
#   "max_split_size_mb:128,expandable_segments"
# Leave empty to use PyTorch defaults.
pytorch_cuda_alloc_conf: "expandable_segments"

# Developer: inkbytefo
# Modified: 2025-11-07

# @package _group_

# AGIFORMER T4 GPU Hardware Configuration
# Settings optimized for NVIDIA T4 GPU training

defaults:
  - _self_

# Device settings
device: cuda
# Use PyTorch CUDA caching allocator with the modern cudaMallocAsync backend.
# See: https://pytorch.org/docs/stable/memory_management.html#torch.cuda.memory.CUDAPluggableAllocator
# This resolves the 'Unknown allocator backend' error.
# pytorch_cuda_alloc_conf: "backend:cudaMallocAsync"

# Memory and performance settings
use_amp: true
amp_dtype: float16
num_workers: 2
pin_memory: true
persistent_workers: true

# Batch size optimization for T4
training:
  batch_size: 1  # Reduced from 2 to prevent CUDA OOM
  gradient_accumulation_steps: 8
  use_gradient_checkpointing: true
  max_grad_norm: 0.5  # Reduce gradient norm to prevent memory spikes

# T4-specific model settings
model:
  d_model: 384  # Reduced from 512
  n_layers: 6   # Reduced from 8
  n_heads: 6    # Reduced from 8
  d_ff: 1536    # Reduced from 2048
  max_seq_len: 256  # Reduced from 512
  use_memory: true
  use_introspection: false  # Disabled for T4
  use_multimodal: false     # Disabled for T4
  use_linear_attention: false
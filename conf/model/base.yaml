# Developer: inkbytefo
# Modified: 2025-11-06

# @package _group_

# AGIFORMER Base Model Configuration
# Default model architecture settings

# Architecture
d_model: 512
n_layers: 8
n_heads: 8
d_ff: 2048
vocab_size: 32000

# Mixture of Experts
n_experts: 4
expert_types: ["language", "knowledge", "spatial", "logic"]

# Memory and Sequence
memory_size: 1000
max_seq_len: 512

# Regularization
dropout: 0.1

# Feature Flags
use_linear_attention: false
use_memory: true
use_introspection: true
use_multimodal: false
use_agglutinative_attention: true
use_gradient_checkpointing: false

# Language-specific settings
morphological_analysis: true
tokenizer_path: tokenizer/morphopiece.model
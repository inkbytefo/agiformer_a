// Developer: inkbytefo
// Modified: 2025-11-07

# Base AGIFORMER model configuration

# Tokenizer & vocabulary
tokenizer_path: /teamspace/studios/this_studio/agiformer_a/tokenizer/morphopiece.model
vocab_size: 256

# Core architecture
d_model: 512
n_layers: 8
n_heads: 8
d_ff: 2048
max_seq_len: 512
dropout: 0.1

# Mixture-of-Experts & experts
n_experts: 4
expert_types:
  - language
  - logic
  - spatial
  - neuro_symbolic

# Memory & introspection
memory_size: 4096
use_memory: true
use_introspection: true

# Attention & multimodality
use_linear_attention: false
use_multimodal: false
use_agglutinative_attention: true

# Training-time features
use_gradient_checkpointing: false
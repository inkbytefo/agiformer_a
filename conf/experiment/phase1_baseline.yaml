# Developer: inkbytefo
# Modified: 2025-11-06

# @package _group_

# AGIFORMER Phase 1 Baseline Experiment Configuration
# Standard Transformer with MultiHeadAttention for comparison with AGIFORMER-Lite

defaults:
  - _self_

# Override model settings for Phase 1 Baseline
model:
  d_model: 512
  n_layers: 6
  n_heads: 8
  d_ff: 2048
  n_experts: 1
  expert_types: ["language"]
  memory_size: 0
  max_seq_len: 512
  use_linear_attention: false
  use_memory: false
  use_introspection: false
  use_multimodal: false
  use_agglutinative_attention: false
  morphological_analysis: false

# Override training settings for Phase 1
training:
  batch_size: 32
  learning_rate: 0.0001
  warmup_steps: 1000
  max_steps: 10000
  epochs: 10
  eval_interval: 500
  log_interval: 100
  save_interval: 1000

# Experiment metadata
experiment_name: phase1_baseline
run_name: phase1_baseline_${now:%Y%m%d_%H%M%S}
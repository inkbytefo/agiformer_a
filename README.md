# AGIFORMER: Experimental AGI Research Framework v0.1

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-Private-green.svg)](LICENSE.txt)
[![Version](https://img.shields.io/badge/Version-0.1.0-orange.svg)](https://github.com/inkbytefo/agiformer_a)

AGIFORMER, Yapay Genel Zeka'ya yÃ¶nelik yenilikÃ§i mimari konseptlerini araÅŸtÄ±ran deneysel bir framework'tÃ¼r. GeliÅŸtirilme aÅŸamasÄ±ndaki bileÅŸenleri (uzmanlaÅŸmÄ±ÅŸ akÄ±l yÃ¼rÃ¼tme motorlarÄ±, bellek sistemi, iÃ§ gÃ¶zlem yetenekleri) bir araya getirerek geleneksel Transformer mimarilerinin Ã¶tesine geÃ§meye yÃ¶nelik kavramsal araÅŸtÄ±rmalar yÃ¼rÃ¼tmektedir.

## âœ¨ Experimental Features (Under Development)

- ğŸ§  **Mixture of Experts (MoE)**: 4 specialized reasoning engines (Language, Logic, Spatial, Causal) - *Conceptual implementation*
- ğŸ¯ **Multimodal Perception**: Text, image, audio and video processing - *Research framework*
- ğŸ’¾ **Advanced Memory System**: Working memory + long-term memory - *Architectural concept*
- ğŸ” **Introspection**: Self-observation and iterative improvement - *Experimental phase*
- ğŸ“ **MorphoPiece Tokenizer**: Turkish morphological awareness tokenization - *Basic implementation*
- ğŸ‡¹ğŸ‡· **Turkish Language Processing**: TMA-1 integration for advanced Turkish understanding - *Development stage*
- âš¡ **Performance Optimizations**: Mixed precision, gradient_checkpointing support - *Infrastructure ready*

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Kurulum

```bash
# Repoyu klonla
git clone https://github.com/inkbytefo/agiformer_a.git
cd agiformer

# Ortam oluÅŸtur
conda create -n agiformer python=3.9
conda activate agiformer

# Kurulum yap
pip install -r requirements.txt
pip install -e .
```

### Ä°lk Deneme

```python
import torch
from agiformer import AGIFORMER

# Model oluÅŸtur
model = AGIFORMER(
    vocab_size=256,
    d_model=384,      # KÃ¼Ã§Ã¼k model iÃ§in hÄ±zlÄ± baÅŸlangÄ±Ã§
    n_layers=2,
    use_multimodal=True,
    use_memory=True,
    use_introspection=True
)

# Metin Ã¼retimi
text = "Merhaba dÃ¼nya!"
char_ids = [ord(c) % 256 for c in text]
input_tensor = torch.tensor([char_ids], dtype=torch.long)

model.eval()
with torch.no_grad():
    generated = model.generate(input_tensor, max_new_tokens=20)

result = ''.join([chr(c % 256) for c in generated[0].cpu().numpy()])
print(f"Ã‡Ä±ktÄ±: {result}")
```

## ğŸ“Š Mimari

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGIFORMER v0.1                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚           TMA-1 (TÃ¼rkÃ§e MantÄ±k AÄŸÄ±)             â”‚     â”‚
â”‚  â”‚        AgglutinativeAttention + Grammar         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Metin     â”‚  â”‚   GÃ¶rÃ¼ntÃ¼   â”‚  â”‚    Ses      â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚               â”‚               â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚        Multimodal Perception Core              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            Memory Backbone                       â”‚     â”‚
â”‚  â”‚    MemoryBank + WorkingMemory + UnifiedMemory   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚          Expert Stack (Mixture of Experts)      â”‚     â”‚
â”‚  â”‚   Language â”‚ Logic â”‚ Spatial â”‚ Causal â”‚ MoE     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              AGIFORMER Block (N layers)         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              Output Projection                   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§© BileÅŸenler

### 1. TMA-1 (TÃ¼rkÃ§e MantÄ±k AÄŸÄ±)
- **AgglutinativeAttention**: TÃ¼rkÃ§e'nin eklemeli yapÄ±sÄ±na Ã¶zel attention mekanizmasÄ±
- **MorphoPiece Tokenizer**: Morfolojik farkÄ±ndalÄ±klÄ± tokenizasyon
- **Grammar Engine**: TÃ¼rkÃ§e dilbilgisi kurallarÄ± ve ses uyumu kontrolÃ¼
- **Morpho Splitter**: Regex ve Java tabanlÄ± morfem ayrÄ±mÄ±

### 2. Uzman Sistemi (MoE)
- **ExpertRouter**: Dinamik uzman yÃ¶nlendirme
- **Language Expert**: Dil iÅŸleme ve morfolojik analiz
- **Logic Expert**: MantÄ±ksal akÄ±l yÃ¼rÃ¼tme
- **Spatial Expert**: Mekansal ve geometrik iÅŸleme
- **Causal Expert**: Nedensel iliÅŸki analizi
- **Neuro-Symbolic Expert**: Sembolik-mantÄ±ksal hibrit akÄ±l yÃ¼rÃ¼tme

### 3. Multimodal AlgÄ±
- **TextEncoder**: Karakter/seviye veya token-seviye metin iÅŸleme
- **ImageEncoder**: CLIP tabanlÄ± gÃ¶rÃ¼ntÃ¼ encoder'Ä±
- **AudioEncoder**: Mel-spektrogram tabanlÄ± ses iÅŸleme
- **VideoEncoder**: Spatio-temporal video analizi

### 4. Bellek Sistemi
- **MemoryBank**: Uzun sÃ¼reli bellek deposu
- **WorkingMemory**: Segment-seviye Ã§alÄ±ÅŸma belleÄŸi
- **UnifiedMemoryBackbone**: TÃ¼mleÅŸik bellek yÃ¶netimi

### 5. Knowledge Graph Sistemi
- **GlobalKnowledgeGraph**: KÃ¼resel bilgi grafiÄŸi
- **DynamicKnowledgeGraph**: Dinamik kavram iliÅŸkileri
- **RelationClassifier**: Ä°liÅŸki tipi sÄ±nÄ±flandÄ±rma

### 6. Ä°Ã§ GÃ¶zlem
- **Self-Model**: Kendi durumunu gÃ¶zlemleme
- **Meta Learning**: Ã–ÄŸrenmeyi Ã¶ÄŸrenme yetenekleri
- **Task Classifier**: GÃ¶rev tipi otomatik sÄ±nÄ±flandÄ±rma
- **Pseudo Labeler**: Otomatik veri etiketleme

## ğŸ“š DÃ¶kÃ¼mantasyon

| DÃ¶kÃ¼mantasyon | AÃ§Ä±klama |
|----------------|----------|
| [ğŸ“– Teknik DÃ¶kÃ¼mantasyon](AGIFORMER_TECHNICAL_DOCUMENTATION.md) | DetaylÄ± mimari ve API referansÄ± |
| [ğŸ¨ Mimari DiyagramlarÄ±](AGIFORMER_ARCHITECTURE_DIAGRAMS.md) | GÃ¶rsel mimari diyagramlarÄ± |
| [âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§](AGIFORMER_QUICK_START_GUIDE.md) | KapsamlÄ± baÅŸlangÄ±Ã§ kÄ±lavuzu |
| [ğŸ““ Colab Rehberi](COLAB_GUIDE.md) | Google Colab'da Ã§alÄ±ÅŸtÄ±rma |

## ğŸ› ï¸ KullanÄ±m

### Temel KullanÄ±m

```python
from agiformer import AGIFORMER

# Model oluÅŸtur
model = AGIFORMER(
    vocab_size=256,
    d_model=768,
    n_layers=12,
    n_heads=12,
    n_experts=4,
    use_multimodal=True,
    use_memory=True,
    use_introspection=True
)

# Ä°leri geÃ§iÅŸ
logits, info = model(text=input_ids, image=image_tensor)

# Metin Ã¼retimi
generated = model.generate(input_ids, max_new_tokens=50)
```

### Multimodal Ä°ÅŸleme

```python
# FarklÄ± modaliteler
logits, info = model(
    text=text_ids,
    image=image_tensor,
    audio=audio_tensor,
    video=video_tensor
)

# Model bilgisi
print(f"Modaliteler: {info['modalities']}")
print(f"Uzman kullanÄ±mÄ±: {info['blocks'][0]['moe']['router_info']['expert_usage']}")
```

### EÄŸitim

```python
# Yeni birleÅŸtirilmiÅŸ eÄŸitim script'i - Hydra konfigÃ¼rasyonu ile
python train.py experiment=phase1_lite hardware=t4_gpu

# FarklÄ± deneyler
python train.py experiment=phase1_baseline hardware=default_gpu
python train.py experiment=phase1_lite hardware=cpu

# Ã–zel veri ile eÄŸitim
python train.py experiment=phase1_lite hardware=t4_gpu data.data_path=turkish_dataset.jsonl

# Mevcut konfigÃ¼rasyonlarÄ± gÃ¶rÃ¼ntÃ¼le
python train.py --help
```

#### KonfigÃ¼rasyon YapÄ±sÄ±

Yeni konfigÃ¼rasyon sistemi Ã¼Ã§ ana kategoriye ayrÄ±lmÄ±ÅŸtÄ±r:

- **`conf/experiment/`**: Deney spesifik ayarlar (phase1_lite, phase1_baseline)
- **`conf/hardware/`**: DonanÄ±m optimizasyonlarÄ± (cpu, t4_gpu, default_gpu)
- **`conf/base/`**: Temel model ve eÄŸitim ayarlarÄ±

#### Ã–rnek KonfigÃ¼rasyonlar

```yaml
# conf/experiment/phase1_lite.yaml
d_model: 512
n_layers: 6
use_agglutinative_attention: true
morphological_analysis: true

# conf/hardware/t4_gpu.yaml
device: cuda
batch_size: 16
use_amp: true
```

## ğŸ§ª Testler

```bash
# TÃ¼m testler
python -m pytest tests/ -v

# BileÅŸen testleri
python examples/multimodal_test.py
python examples/moe_test.py
python examples/memory_test.py
python examples/introspection_test.py

# KonfigÃ¼rasyon testi
python test_fix.py
```

## ğŸ“ˆ Current Development Status

### Framework Architecture (Under Development)
- **Basic Model Framework**: Conceptual implementation of MoE architecture
- **Memory Usage**: Infrastructure ready for memory optimization
- **Training Pipeline**: Basic training loop with room for optimization
- **Research Focus**: Architectural experimentation, not performance benchmarking

### Infrastructure Status
- âœ… Mixed precision training infrastructure
- âœ… Gradient checkpointing support
- âœ… Configurable model architecture
- ğŸ”„ Training optimization (in progress)

## ğŸ¯ Research Vision (Long-term Goals)

**Note**: The following represents our long-term research vision and experimental goals, not current achieved results.

### Target Performance Goals
- **SOTA Reasoning**: Mixture of Experts for specialized cognitive tasks
- **Multimodal Integration**: Unified text, image, audio, video understanding
- **Advanced Memory**: Persistent knowledge and context awareness
- **Self-Introspection**: Meta-learning and self-improvement capabilities
- **Turkish Language Mastery**: Native-level Turkish language understanding

**Important**: These are research objectives and experimental goals, not currently achieved benchmarks. The project is in early research and development phase.

## ğŸ¯ Ã–rnekler

### 1. Metin Ãœretimi
```python
# YaratÄ±cÄ± metin Ã¼retimi
prompt = "Gelecekte yapay zeka"
generated = model.generate(prompt_ids, temperature=1.2, top_p=0.9)
```

### 2. GÃ¶rÃ¼ntÃ¼-Metin
```python
# GÃ¶rÃ¼ntÃ¼ aÃ§Ä±klama
image = load_image("example.jpg")
logits, info = model(text=prompt_ids, image=image)
```

### 3. Bellek Analizi
```python
# Bellek kullanÄ±mÄ±nÄ± izle
logits, info = model(text=input_ids)
memory_info = info['memory']
print(f"Bellek adÄ±mlarÄ±: {memory_info['step_count']}")
```

## ğŸ”§ KonfigÃ¼rasyon

### Temel KonfigÃ¼rasyon ([`configs/base_config.yaml`](configs/base_config.yaml))
```yaml
model:
  vocab_size: 256
  d_model: 768
  n_layers: 12
  n_heads: 12
  n_experts: 4
  expert_types: ["language", "logic", "spatial", "causal"]
  use_memory: true
  use_introspection: true
  use_multimodal: true

training:
  batch_size: 32
  learning_rate: 0.0001
  use_amp: true
```

### Colab KonfigÃ¼rasyonu ([`configs/colab_config.yaml`](configs/colab_config.yaml))
- Daha kÃ¼Ã§Ã¼k model boyutu
- AzaltÄ±lmÄ±ÅŸ batch size
- Optimize edilmiÅŸ for Colab

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
agiformer/
â”œâ”€â”€ agiformer/                 # Ana paket
â”‚   â”œâ”€â”€ core/                 # Ã‡ekirdek bileÅŸenler
â”‚   â”‚   â”œâ”€â”€ attention.py      # MultiHead, Linear, SyntaxAware, CrossModal attention
â”‚   â”‚   â”œâ”€â”€ base_components.py # LayerNorm, PositionalEncoding, FeedForward
â”‚   â”‚   â”œâ”€â”€ memory_backbone.py # MemoryBank, WorkingMemory, UnifiedMemoryBackbone
â”‚   â”‚   â””â”€â”€ multimodal_perception.py # Text/Image/Audio/Video encoders
â”‚   â”œâ”€â”€ language/             # TÃ¼rkÃ§e dil iÅŸleme modÃ¼lleri (TMA-1)
â”‚   â”‚   â”œâ”€â”€ model.py          # TMA1Model (TÃ¼rkÃ§e MantÄ±k AÄŸÄ±)
â”‚   â”‚   â”œâ”€â”€ attention.py      # AgglutinativeAttention (eklemeli yapÄ±)
â”‚   â”‚   â”œâ”€â”€ morpho_splitter.py # Regex ve Java tabanlÄ± morfem ayrÄ±mÄ±
â”‚   â”‚   â”œâ”€â”€ tokenizer.py      # MorphoPiece tokenizer
â”‚   â”‚   â””â”€â”€ grammar_engine.py # TÃ¼rkÃ§e dilbilgisi kurallarÄ± motoru
â”‚   â”œâ”€â”€ experts/              # Mixture of Experts sistemi
â”‚   â”‚   â”œâ”€â”€ moe.py           # ExpertRouter, Expert, MixtureOfExperts
â”‚   â”‚   â”œâ”€â”€ language_expert.py # Dil uzmanÄ±
â”‚   â”‚   â”œâ”€â”€ logic_expert.py   # MantÄ±k uzmanÄ±
â”‚   â”‚   â”œâ”€â”€ spatial_expert.py # Mekansal uzman
â”‚   â”‚   â”œâ”€â”€ causal_expert.py  # Nedensel uzman
â”‚   â”‚   â”œâ”€â”€ knowledge_graph.py # Global/Dynamic knowledge graphs
â”‚   â”‚   â”œâ”€â”€ neuro_symbolic_expert.py # Neuro-symbolic reasoning
â”‚   â”‚   â”œâ”€â”€ pseudo_labeler.py # Otomatik etiketleme
â”‚   â”‚   â”œâ”€â”€ task_classifier.py # GÃ¶rev tipi sÄ±nÄ±flandÄ±rma
â”‚   â”‚   â””â”€â”€ relations.py      # Ä°liÅŸki iÅŸleme
â”‚   â”œâ”€â”€ introspection/        # Ä°Ã§ gÃ¶zlem sistemi
â”‚   â”‚   â”œâ”€â”€ self_model.py    # Self-model gÃ¶zlemi
â”‚   â”‚   â””â”€â”€ meta_learning.py # Meta-Ã¶ÄŸrenme
â”‚   â”œâ”€â”€ data/                 # BirleÅŸtirilmiÅŸ veri iÅŸleme modÃ¼lÃ¼
â”‚   â”‚   â””â”€â”€ dataset.py        # TÃ¼m dataset sÄ±nÄ±flarÄ± (TurkishTextDataset, TextDataset, vb.)
â”‚   â”œâ”€â”€ datasets/             # Multimodal veri setleri
â”‚   â”‚   â”œâ”€â”€ base_dataset.py   # Temel dataset sÄ±nÄ±fÄ±
â”‚   â”‚   â””â”€â”€ cc_datasets.py    # Common Crawl veri iÅŸleme
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py              # AGIFORMER ana model
â”‚   â”œâ”€â”€ data_quality.py       # Veri kalitesi kontrolÃ¼
â”‚   â””â”€â”€ utils.py              # YardÄ±mcÄ± fonksiyonlar
â”œâ”€â”€ conf/                     # Yeni konfigÃ¼rasyon yapÄ±sÄ±
â”‚   â”œâ”€â”€ config.yaml           # Ana konfigÃ¼rasyon giriÅŸi
â”‚   â”œâ”€â”€ base/                 # Temel ayarlar
â”‚   â”‚   â”œâ”€â”€ model.yaml        # Temel model mimarisi
â”‚   â”‚   â””â”€â”€ training.yaml     # Temel eÄŸitim ayarlarÄ±
â”‚   â”œâ”€â”€ experiment/           # Deney spesifik konfigÃ¼rasyonlar
â”‚   â”‚   â”œâ”€â”€ phase1_lite.yaml  # Hafif model deneyi
â”‚   â”‚   â””â”€â”€ phase1_baseline.yaml # KarÅŸÄ±laÅŸtÄ±rma deneyi
â”‚   â”œâ”€â”€ hardware/             # DonanÄ±m optimizasyonlarÄ±
â”‚   â”‚   â”œâ”€â”€ cpu.yaml          # CPU optimizasyonu
â”‚   â”‚   â”œâ”€â”€ t4_gpu.yaml       # T4 GPU optimizasyonu
â”‚   â”‚   â””â”€â”€ default_gpu.yaml  # VarsayÄ±lan GPU ayarlarÄ±
â”‚   â”œâ”€â”€ logging/              # Log ayarlarÄ±
â”‚   â””â”€â”€ model/                # Eski model konfigÃ¼rasyonlarÄ± (arÅŸiv)
â”œâ”€â”€ archive/                  # ArÅŸivlenmiÅŸ eski script'ler
â”‚   â”œâ”€â”€ train_phase1.py       # Eski Phase 1 eÄŸitim script'i
â”‚   â”œâ”€â”€ training_example.py   # Eski eÄŸitim Ã¶rneÄŸi
â”‚   â”œâ”€â”€ quick_test.py         # Eski test script'i
â”‚   â””â”€â”€ old_train_backup.py    # Eski train.py yedeÄŸi
â”œâ”€â”€ examples/                 # KullanÄ±m Ã¶rnekleri
â”œâ”€â”€ scripts/                  # YardÄ±mcÄ± script'ler
â”‚   â”œâ”€â”€ analyze_data_quality.py
â”‚   â”œâ”€â”€ clean_corpus.py
â”‚   â”œâ”€â”€ download_real_datasets.py
â”‚   â”œâ”€â”€ prepare_cc12m.py
â”‚   â”œâ”€â”€ preprocess_language_data.py
â”‚   â””â”€â”€ train_tokenizer.py
â”œâ”€â”€ tests/                    # Testler
â””â”€â”€ train.py                  # Yeni birleÅŸtirilmiÅŸ eÄŸitim script'i
```

## ğŸ¤ KatkÄ±

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. Commit yapÄ±n (`git commit -m 'Add some AmazingFeature'`)
4. Push yapÄ±n (`git push origin feature/AmazingFeature`)
5. Pull request aÃ§Ä±n

### GeliÅŸtirme Kurulumu

```bash
# GeliÅŸtirme ortamÄ±
git clone https://github.com/inkbytefo/agiformer_a.git
cd agiformer

# Development modunda kur
pip install -e ".[dev]"

# Testleri Ã§alÄ±ÅŸtÄ±r
python -m pytest tests/ -v

# Kod formatlama
black agiformer/
flake8 agiformer/
```

## ğŸ“„ Lisans

Bu proje **Ã¶zel mÃ¼lkiyet lisansÄ±** altÄ±nda lisanslanmÄ±ÅŸtÄ±r - [LICENSE.txt](LICENSE.txt) dosyasÄ±na bakÄ±n. TÃ¼m fikri mÃ¼lkiyet haklarÄ± Tevfik Ä°ÅŸkÄ±n'a aittir.

## ğŸ™ TeÅŸekkÃ¼rler

- **Transformer** mimarisi
- **Mixture of Experts** araÅŸtÄ±rmalarÄ±
- **CLIP** multimodal Ã¶ÄŸrenme
- **Charformer** morfo-semantik tokenizasyon
- **Transformer-XL** bellek mekanizmalarÄ±

## ğŸ“ Ä°letiÅŸim

- **Proje**: https://github.com/yourusername/agiformer
- **Issues**: https://github.com/yourusername/agiformer/issues
- **Discussions**: https://github.com/yourusername/agiformer/discussions

## ğŸ—ºï¸ Development Roadmap

### Current Status (v0.1)
- âœ… Basic framework architecture
- âœ… Initial MoE conceptual implementation
- âœ… Training infrastructure setup
- ğŸ”„ Real dataset integration (in progress)
- ğŸ”„ Component testing and validation

### v0.2 (Next Development Phase)
- [ ] Complete real dataset training verification
- [ ] Enhanced MoE expert implementations
- [ ] Improved memory system architecture
- [ ] Basic multimodal integration testing

### v0.3 (Long-term Research Goals)
- [ ] Advanced expert specializations
- [ ] Distributed training capabilities
- [ ] Mobile optimization research
- [ ] API service development

**Note**: All roadmap items are development goals, not guaranteed deliverables. This is research-focused experimental work.

---

<div align="center">

**AGIFORMER** - Yapay Genel Zeka'ya giden yolculukta bir adÄ±m

[![Star](https://img.shields.io/github/stars/yourusername/agiformer.svg?style=social&label=Star)](https://github.com/inkbytefo/agiformer_a)
[![Fork](https://img.shields.io/github/forks/yourusername/agiformer.svg?style=social&label=Fork)](https://github.com/inkbytefo/agiformer_a/fork)
[![Watch](https://img.shields.io/github/watchers/yourusername/agiformer.svg?style=social&label=Watch)](https://github.com/inkbytefo/agiformer_a)

</div>
